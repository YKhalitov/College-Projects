{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "wgORba5AKB7k"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import tensorflow as tf\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torchvision.io import read_image\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "\n",
        "import albumentations as A\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip public_tests.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZqK8XegKa2_",
        "outputId": "b7af1c15-b483-4076-f537-b7fbeefdd612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  public_tests.zip\n",
            "replace 00_test_img_gt/gt.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = models.mobilenet_v2(pretrained=True)\n",
        "# model.to(device)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "num_ftrs = model.classifier[-1].in_features\n",
        "model.classifier[-1] = nn.Linear(num_ftrs, 50) # 50 species\n"
      ],
      "metadata": {
        "id": "CiuW68TRCID0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, images_per_class=50, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.images_per_class = images_per_class\n",
        "        self.images = sorted(os.listdir(root_dir))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.images[idx])\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = idx // self.images_per_class\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "vl4gerehKOuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize images to the desired size\n",
        "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize pixel values\n",
        "])"
      ],
      "metadata": {
        "id": "A3cn3VG9KMPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "num_train_per_class = 40\n",
        "num_val_per_class = 10\n",
        "\n",
        "# List to store indices of images for training and validation\n",
        "train_indices = []\n",
        "val_indices = []\n",
        "\n",
        "# Iterate over classes\n",
        "for class_idx in range(50):\n",
        "    # List all image filenames for the current class\n",
        "    class_images = [f'{class_idx:04d}.jpg' for class_idx in range(class_idx * 50 + 1, (class_idx + 1) * 50 + 1)]\n",
        "    # Shuffle the image filenames\n",
        "    random.shuffle(class_images)\n",
        "    # Assign indices for training and validation sets\n",
        "    train_indices.extend(class_images[:num_train_per_class])\n",
        "    val_indices.extend(class_images[num_train_per_class:])\n",
        "\n",
        "# Create subsets for training and validation\n",
        "train_dataset = Subset(CustomDataset(root_dir='00_test_img_input/train/images'), train_indices)\n",
        "val_dataset = Subset(CustomDataset(root_dir='00_test_img_input/train/images'), val_indices)\n",
        "\n",
        "# Create data loaders for training and validation\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "VMP0FCiQLgTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data = CustomDataset('00_test_img_input/train/images', images_per_class=50, transform=data_transform)\n",
        "\n",
        "\n",
        "\n",
        "# train_data_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "\n",
        "# valid_data = CustomDataset('00_test_img_input/test/images', images_per_class=50, transform=data_transform)\n",
        "# valid_data_loader = DataLoader(valid_data, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "g7f6Vm4BCem4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam"
      ],
      "metadata": {
        "id": "5WAHETxFRVBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "creterion = nn.CrossEntropyLoss()\n",
        "creterion.to(device)\n",
        "optimizer = Adam(model.parameters())\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "1URLg8ulTZVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "uY5i3uRYZHTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 15\n",
        "best_accuracy = 0\n",
        "early_stopping_counter = 0\n",
        "early_stopping_limit = 5  # Adjust as needed\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  for x, y in tqdm(train_loader):\n",
        "    # x, y = x.to(device), y.to(device)\n",
        "    y_pred = model(x)\n",
        "    loss = creterion(y_pred, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  model.eval()\n",
        "  val_predictions = []\n",
        "  val_targets = []\n",
        "  with torch.no_grad():\n",
        "    for x, y in tqdm(val_loader):\n",
        "      # x, y = x.to(device), y.to(device)\n",
        "      y_pred = model(x)\n",
        "      val_predictions.extend(torch.argmax(y_pred, dim=1).cpu().tolist())\n",
        "      val_targets.extend(y.cpu().y.tolist())\n",
        "\n",
        "  accuracy = accuracy_score(val_targets, val_predictions)\n",
        "\n",
        "  if accuracy > best_accuracy:\n",
        "    best_accuracy = accuracy\n",
        "    early_stopping_counter = 0\n",
        "  else:\n",
        "    early_stopping_counter += 1\n",
        "\n",
        "  if early_stopping_counter == early_stopping_limit:\n",
        "    print(f'Early stopping at epoch {epoch} due to lack of improvement in validation accuracy.')\n",
        "    break\n",
        "\n",
        "  print(f'Epoch {epoch}: Validation Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "xVggunuHTzdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchvision import transforms\n",
        "# from PIL import Image\n",
        "\n",
        "# # base transformations\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Grayscale(),\n",
        "#     transforms.ToTensor(),\n",
        "# ])\n",
        "\n",
        "\n",
        "# def predict_number(image_path):\n",
        "#     image = Image.open(image_path)\n",
        "#     image = transform(image).unsqueeze(0)\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         output = model(image)\n",
        "\n",
        "#     _, predicted = torch.max(output, 1)\n",
        "#     return predicted.item(), image\n",
        "\n",
        "# image_paths = [\"Centered_8.png\", \"Centered_3.png\", \"Uncentered_3.png\"]\n",
        "\n",
        "# for image_path in image_paths:\n",
        "#     predicted_number, image = predict_number(image_path)\n",
        "\n",
        "#     plt.imshow(image.squeeze(), cmap='gray')\n",
        "#     plt.title(f\"Predicted Number: {predicted_number}\")\n",
        "#     plt.axis('off')\n",
        "#     plt.show()\n",
        "\n",
        "# torch.save(model.state_dict(), \"model_weights.pth\")"
      ],
      "metadata": {
        "id": "9b5B4sJQUgqx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}